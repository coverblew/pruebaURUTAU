Tema 6

Gestión de proyectos IA: estructura de un proyecto IA y su despliegue

Investigación y Gestión de Proyectos en Inteligencia Artificial

Índice

[Esquema 3](#_Toc154154615)

[Ideas clave 4](#_Toc154154616)

[6.1. Introducción y objetivos 4](#_Toc154154617)

[6.2. Análisis del problema e identificación alcance de la solución de inteligencia artificial 5](#_Toc154154618)

[6.3. Evaluación de herramientas y plataformas de inteligencia artificial 7](#_Toc154154619)

[6.4. Gestión y preparación de datos para el entrenamiento de modelos 14](#_Toc154154620)

[6.5. Entrenamiento, validación y evaluación de modelos de inteligencia artificial 17](#_Toc154154621)

[6.6. Integración y despliegue de modelos en un entorno productivo empresarial 20](#_Toc154154622)

[6.7. Referencias bibliográficas 23](#_Toc154154623)

[A fondo 24](#_Toc154154624)

[Test 25](#_Toc154154625)

Esquema

![](data:image/jpeg;base64...)

Ideas clave

6.1. Introducción y objetivos

El **proceso de implementación** de proyectos de inteligencia artificial (IA) o ciclo de vida de un proyecto de inteligencia artificial ya se mencionó en el tema sobre el enfoque metodológico. Este capítulo se dedica íntegramente a profundizar en las **diferentes etapas** que lo componen.

El **ciclo de vida de un proyecto** desde el punto de vista de sus estructura, se inicia con el **análisis** y definición de cuál será la solución de inteligencia artificial que se persigue como **objetivo.** En dicha solución también deben considerarse las **herramientas y plataformas** de inteligencia artificial que se utilizarán en el proyecto.

A continuación, nos enfrentaremos a la **gestión y preparación** de los datos necesarios para el entrenamiento de los modelos de inteligencia artificial, lo que es una parte esencial para garantizar el éxito del proyecto.

Posteriormente se aborda el **entrenamiento, validación y evaluación** de modelos de inteligencia artificial elaborados, que son las etapas centrales en el desarrollo de soluciones basadas en inteligencia artificial.

Asimismo, la implementación del proyecto requiere su despliegue en un **entorno productivo empresarial,** lo que es fundamental para asegurar su adopción y utilización efectiva.

Finalmente, el proyecto debe incluir el **proceso de monitorización y mantenimiento** de los modelos de inteligencia artificial que se encuentran en producción para garantizar que la solución de inteligencia artificial siga siendo efectiva y útil con el tiempo.

6.2. Análisis del problema e identificación alcance de la solución de inteligencia artificial

Este apartado describe el proceso de **análisis y definición del alcance de la solución de inteligencia artificial,** que implica entender las **necesidades del negocio** y definir el problema que se va a abordar. Se explora cómo se pueden identificar las variables clave, establecer métricas de éxito y definir el alcance del proyecto.

Análisis del problema

El **análisis del problema** es el primer paso en la definición de una solución de inteligencia artificial. Este proceso implica entender claramente el problema que se quiere **resolver e identificar los objetivos** que se persiguen.

Antes de comenzar a diseñar una solución de inteligencia artificial, es esencial comprender las **necesidades y objetivos del negocio.** Esto implica reunirse con los interesados clave, como directivos, empleados y clientes, para discutir sus expectativas y requisitos. También es importante analizar la información disponible sobre el **rendimiento actual** del negocio y los **desafíos** a los que se enfrenta. Esta investigación inicial ayudará a identificar las áreas en las que la IA podría proporcionar valor y a definir el problema que se va a abordar.

Es importante tener en cuenta que este **análisis** debe ser los suficientemente detallado tanto desde el punto de vista empresarial como técnico.

* **Desde el punto de vista empresarial** para tener en cuenta los requisitos de negocio y las restricciones del proyecto, como el presupuesto, el plazo y los recursos disponibles.
* **Desde el punto de vista técnico** para poder evaluar si la solución se puede abordar desde un proyecto de inteligencia artificial y, en caso afirmativo, poder proporcionar en la siguiente etapa de definición los modelos y algoritmos más adecuadas para resolver el problema.

La comprensión de estos factores ayudará a identificar el alcance de una solución de inteligencia artificial que sea práctica y eficaz.

Establecimiento de métricas de éxito

Para evaluar el éxito de un proyecto de IA, es necesario establecer **métricas cuantificables** que se alineen con los objetivos del negocio. Estas métricas pueden incluir **factores** como la precisión de las predicciones, la reducción de costes o el aumento de la eficiencia. Es importante definir estas métricas desde el principio, para que todos los interesados tengan una comprensión clara de lo que se considera un resultado exitoso.

Definición del alcance de la solución

La **definición del alcance de la solución** es el siguiente paso en la implementación de un proyecto de inteligencia artificial. Definir el alcance del proyecto de IA es fundamental para **mantener el enfoque y controlar los recursos.** El alcance debe incluir los objetivos específicos, las entregas, los plazos y los recursos necesarios para llevar a cabo el proyecto. Además, es útil establecer los límites del proyecto, identificando aquellas áreas que no serán abordadas o las limitaciones de la solución propuesta. Al definir el alcance, es importante ser realista y tener en cuenta las restricciones de tiempo, recursos y conocimientos técnicos disponibles.

Para definir este alcance previamente se debe realizar una **primera aproximación** a lo que podría ser la arquitectura de la solución, que incluye los siguientes elementos:

* **Identificación de las fuentes de datos disponibles o necesarias:** esto puede incluir fuentes de datos internas, como bases de datos empresariales o registros de transacciones; o fuentes externas, como datos públicos o adquiridos a través de proveedores de datos. Además, es importante tener en cuenta las consideraciones éticas y legales al utilizar los datos. Esto puede incluir el aseguramiento de la privacidad y la protección de los datos personales.
* **Selección de algoritmos y el diseño de modelos**: es importante tener en cuenta que la solución de inteligencia artificial puede implicar el uso de una o más técnicas de inteligencia artificial, como el aprendizaje automático, el procesamiento de lenguaje natural o la visión por computadora. Aunque en la fase de definición del alcance la solución es probable que no se tengan aún todo el detalle de los modelos que se emplearán en la construcción de la solución, sí es relevante identificar una primera aproximación por el impacto que pudieran tener en los recursos a emplear y por estar también condicionados por las limitaciones y requisitos empresariales.
* **Recursos a emplear:** debe anticiparse qué recursos de computación y almacenamiento, entre otros, serán necesarios para la construcción de la solución y deben ser coherentes con los requisitos empresariales y los recursos disponibles para el proyecto.

6.3. Evaluación de herramientas y plataformas de inteligencia artificial

El **desarrollo y la adopción de herramientas y plataformas** de inteligencia artificial (IA) han experimentado un rápido crecimiento en las últimas décadas. Desde los primeros sistemas expertos en los años 70 y 80 hasta las modernas bibliotecas de aprendizaje profundo y las plataformas de aprendizaje automático como servicio (MLaaS), la evolución de las herramientas y plataformas de IA ha sido impulsada por avances en la investigación, el *hardware* y la creciente disponibilidad de datos.

Esta evolución ha llevado a la creación de una **amplia variedad de soluciones** que permiten a los profesionales y organizaciones aplicar la IA en diferentes dominios y casos de uso. Algunas de las opciones populares incluyen TensorFlow, PyTorch, scikit-learn, Azure Machine Learning, Google Cloud AI, AWS SageMaker, IBM Watson, entre otros.

Este apartado se centra en la **identificación de los factores a considerar en la selección de herramientas y plataformas de inteligencia artificial** y cómo evaluarlas en función de las necesidades del proyecto.

Categorización de herramientas y plataformas IA

Las herramientas y plataformas de IA pueden clasificarse en **varias categorías,** según su enfoque, funcionalidades y el perfil de los usuarios previstos. Algunas de las categorías más comunes incluyen:

* Plataformas de aprendizaje automático como servicio (MLaaS): Estas plataformas proporcionan un entorno basado en la nube para el desarrollo, entrenamiento y despliegue de modelos de aprendizaje automático. Ejemplos de estas plataformas incluyen Google Cloud AI Platform, Microsoft Azure Machine Learning y Amazon SageMaker.
  + **Google Cloud AI Platform:** esta plataforma ofrece una variedad de servicios de IA y aprendizaje automático, incluida la creación, el entrenamiento y el despliegue de modelos, así como servicios de preprocesamiento de datos y análisis de modelos.
  + **Microsoft Azure Machine Learning:** Azure Machine Learning es un servicio en la nube de Microsoft que ofrece herramientas y servicios para el desarrollo y despliegue de modelos de aprendizaje automático en una variedad de escenarios.
  + **Amazon SageMaker: SageMaker:** es una plataforma de Amazon Web Services (AWS) que permite a los desarrolladores crear, entrenar y desplegar modelos de aprendizaje automático de manera rápida y fácil.
* **Bibliotecas y *frameworks* de IA de código abierto:** las bibliotecas y *frameworks* de código abierto permiten a los desarrolladores personalizar e implementar algoritmos de IA y técnicas de aprendizaje automático. Algunas bibliotecas y *frameworks* notables incluyen TensorFlow, PyTorch, scikit-learn y Keras.
  + **TensorFlow:** desarrollado por Google, TensorFlow es un *framework* de código abierto para la computación numérica y el aprendizaje automático que permite a los desarrolladores crear y entrenar redes neuronales y otros modelos de aprendizaje automático.
  + **PyTorch:** desarrollado por Facebook, es un *framework* de código abierto para la computación numérica y el aprendizaje automático basado en Python. Es especialmente popular entre los investigadores de IA debido a su flexibilidad y facilidad de uso.
  + **scikit-learn:** es una biblioteca de código abierto para Python que ofrece herramientas simples y eficientes para la minería de datos y el análisis de datos. Incluye una amplia gama de algoritmos de aprendizaje supervisado y no supervisado, así como herramientas para la selección y evaluación de modelos.
  + **Keras:** es una interfaz de alto nivel para la creación y el entrenamiento de modelos de aprendizaje profundo. Se puede utilizar junto con TensorFlow, Microsoft Cognitive Toolkit o Theano como *backend*, lo que permite a los desarrolladores aprovechar las capacidades de estos *frameworks* de bajo nivel.
* **Herramientas de desarrollo de IA específicas del dominio:** estas herramientas se centran en casos de uso específicos, como el procesamiento del lenguaje natural (NLP), la visión por computadora o el análisis de datos. Ejemplos de estas herramientas incluyen OpenCV y SpaCy.
  + **OpenCV (Open Source Computer Vision Library):** es una biblioteca de código abierto que proporciona herramientas y funciones para el procesamiento de imágenes y la visión por computadora. Es ampliamente utilizado en aplicaciones de detección y reconocimiento de objetos, seguimiento de objetos en movimiento y análisis de imágenes y vídeos.
  + **spaCy:** es una biblioteca de código abierto para el procesamiento avanzado del lenguaje natural en Python. Incluye funcionalidades para el análisis de texto, la extracción de entidades, el etiquetado gramatical y la clasificación de texto, entre otras tareas de NLP.
* **Plataformas de automatización de procesos robóticos (RPA) con capacidades de IA:** estas plataformas permiten automatizar tareas repetitivas y basadas en reglas utilizando robots de *software* y pueden integrar funcionalidades de IA para mejorar la eficiencia y adaptabilidad. Ejemplos de plataformas RPA incluyen Automation Anywhere y Blue Prism.
  + **Automation Anywhere:** es una plataforma de RPA que combina la automatización de procesos con tecnologías de IA, como el reconocimiento óptico de caracteres (OCR) y el análisis de texto, para permitir la automatización de tareas de mayor complejidad.
  + **Blue Prism:** es otra plataforma de RPA que ofrece integraciones con soluciones de IA y aprendizaje automático, que permite a los usuarios aprovechar estas tecnologías para mejorar la eficiencia y la precisión en la automatización de procesos empresariales.

Beneficios y desafíos de utilizar herramientas y plataformas IAA

Las herramientas y plataformas de IA ofrecen una serie de **beneficios:**

* **Reducción del tiempo de desarrollo:** al proporcionar acceso a algoritmos y recursos predefinidos, las herramientas y plataformas de IA pueden acelerar el proceso de desarrollo y reducir la curva de aprendizaje para los desarrolladores.
* **Facilitar la experimentación y la iteración:** las herramientas y plataformas de IA permiten a los equipos probar rápidamente diferentes enfoques y algoritmos, y facilitan la mejora iterativa de las soluciones.
* **Escalabilidad y rendimiento:** muchas plataformas de IA, especialmente aquellas basadas en la nube ofrecen la posibilidad de escalar los recursos informáticos según las necesidades del proyecto, lo que permite afrontar desafíos de mayor envergadura y complejidad.
* **Soporte y comunidad:** las herramientas y plataformas de IA populares suelen contar con una comunidad activa de desarrolladores y expertos en la materia, que pueden proporcionar soporte y orientación en la implementación y solución de problemas.

Sin embargo, también existen **desafíos** al utilizar herramientas y plataformas de IA, como:

* **Coste:** algunas herramientas y plataformas de IA, especialmente las soluciones empresariales, pueden tener un coste elevado, lo que puede ser un obstáculo para organizaciones con presupuestos limitados.
* **Dependencia de proveedores:** la elección de una herramienta o plataforma específica puede generar una dependencia del proveedor, lo que puede complicar la transición a otra solución en el futuro.
* **Complejidad técnica:** a pesar de la disponibilidad de herramientas y plataformas de IA fáciles de usar, algunas soluciones aún requieren conocimientos técnicos especializados para ser utilizadas de manera efectiva.
* **Consideraciones éticas y de privacidad:** el uso de herramientas y plataformas de IA puede generar preocupaciones relacionadas con la privacidad y la ética, especialmente en el caso de soluciones basadas en la nube o aquellas que involucran el uso de datos sensibles.

Factores clave a considerar al evaluar herramientas y plataformas IA

Al evaluar herramientas y plataformas de IA, es importante considerar los siguientes **factores:**

**Facilidad de uso**

Algunas soluciones están diseñadas para ser **más accesibles** para usuarios no técnicos, con interfaces gráficas de usuario y funciones de arrastrar y soltar, mientras que otras pueden requerir **habilidades de codificación y conocimientos especializados.** La elección dependerá del nivel de experiencia del equipo y de las capacidades de aprendizaje.

**Escalabilidad**

La escalabilidad se refiere a la capacidad de una herramienta o plataforma de IA para **adaptarse a las necesidades de crecimiento y expansión de un proyecto.** Es importante seleccionar soluciones que puedan adaptarse a las necesidades cambiantes del proyecto y manejar grandes volúmenes de datos y usuarios, especialmente si se trata de proyectos que pueden crecer en tamaño y complejidad.

**Soporte y comunidad**

El **soporte y la comunidad** que rodea a una herramienta o plataforma de IA pueden ser esenciales para el éxito del proyecto. Una comunidad activa y un buen soporte técnico pueden facilitar la resolución de problemas y proporcionar orientación y recursos valiosos. Además, el compromiso del proveedor con el desarrollo continuo y la mejora de la herramienta o plataforma son aspectos importantes a considerar.

**Integración y compatibilidad**

La capacidad de **integrar** la herramienta o plataforma de IA seleccionada con otras soluciones y sistemas existentes en la organización es un factor relevante. Es importante, por lo tanto, evaluar la **compatibilidad con las tecnologías y las infraestructuras** ya utilizadas, así como la disponibilidad de APIs y otros mecanismos de integración.

**Seguridad y cumplimiento**

La solución seleccionada debe cumplir con las **políticas y regulaciones de seguridad de la información** aplicables, así como con los estándares éticos y de privacidad. Esto incluye el almacenamiento y procesamiento de datos sensibles y la implementación de medidas de protección adecuadas. Algunos aspectos a considerar incluyen los siguientes:

* **Protección de datos:** evaluar las medidas de seguridad implementadas por la herramienta o plataforma para proteger los datos almacenados y en tránsito. Esto incluye la encriptación, el control de acceso y la monitorización de las actividades de los usuarios.
* **Almacenamiento y procesamiento de datos**: considerar dónde se almacenan y procesan los datos, especialmente si la solución es basada en la nube. Prestar atención a las leyes y regulaciones aplicables en diferentes jurisdicciones, como el Reglamento General de Protección de Datos (GDPR) en la Unión Europea.
* **Políticas de privacidad y uso de datos:** revisar las políticas de privacidad y uso de datos de la herramienta o plataforma para asegurarse de que estén alineadas con las políticas de la organización y las expectativas de los clientes y usuarios finales.
* **Auditoría y seguimiento:** asegurarse de que la herramienta o plataforma permita llevar a cabo auditorías y seguimiento de las actividades relacionadas con la IA, lo que puede ser útil para identificar posibles problemas de seguridad y garantizar el cumplimiento normativo.
* **Gestión de incidentes y respuesta a brechas:** evaluar las capacidades de la herramienta o plataforma para detectar y responder a incidentes de seguridad y brechas de datos, así como las políticas y procesos establecidos por el proveedor en caso de un incidente.

**Coste**

Al evaluar los costes de las diferentes herramientas y plataformas de IA, es importante considerar el **ROI potencial y determinar si el gasto está justificado** en función del valor que la solución de IA puede aportar al proyecto y a la organización en general. Los **elementos a considerar** son los siguientes:

* **Coste inicial:** algunas herramientas y plataformas de IA requieren una inversión inicial, ya sea en términos de licencias de *software*, suscripciones o *hardware* especializado. Es esencial comparar estos costos iniciales con el presupuesto del proyecto y el valor potencial de la solución de IA.
* **Costes operativos:** además del costo inicial, también se deben considerar los costos operativos a lo largo del tiempo. Estos pueden incluir tarifas de suscripción recurrentes, costos de almacenamiento y procesamiento de datos, y costos de mantenimiento de *hardware* y *software*.
* **Costes de personal:** el desarrollo e implementación de soluciones de IA puede requerir la contratación o capacitación de personal especializado, lo que puede aumentar los costes del proyecto. Es fundamental considerar estos costes de personal al evaluar las herramientas y plataformas de IA.
* **Costes de transición e integración:** si se decide cambiar de una herramienta o plataforma a otra, puede haber costes asociados con la transición, como la migración de datos, la capacitación de empleados y la integración con sistemas existentes.

6.4. Gestión y preparación de datos para el entrenamiento de modelos

En este apartado se tratará todo lo relacionado con **la selección y preparación de los datos necesarios para el entrenamiento de los modelos de inteligencia artificial.** La **calidad de los datos de entrada** es uno de los factores más importantes en la creación de modelos de inteligencia artificial efectivos. Es por eso que una gestión y preparación adecuada de los datos es esencial para el éxito del proyecto.

En esta sección, se explorarán algunas de las **técnicas y prácticas comunes** utilizadas en la gestión y preparación de datos para el entrenamiento de modelos de inteligencia artificial.

Recopilación de datos

El primer paso en la gestión y preparación de datos es la **recopilación de datos.** Los datos pueden provenir de **diferentes fuentes,** como sistemas de registro, sensores, bases de datos, redes sociales, páginas web, entre otras. Es importante tener en cuenta que los datos deben estar en un **formato que sea adecuado** para el modelo de inteligencia artificial que se está creando. Además, es importante asegurarse de que los datos sean relevantes y útiles para el problema que se está tratando de resolver.

Limpieza de datos

Una vez que se han recopilado los datos, es necesario limpiarlos. La **limpieza de datos** es el proceso de eliminar datos duplicados, incompletos, inconsistentes o irrelevantes. La limpieza de datos puede ser un proceso tedioso, pero es necesario para garantizar que el modelo se entrene con **datos precisos y confiables.**

Existen **diferentes técnicas** para la limpieza de datos, como la eliminación de valores atípicos, la interpolación de valores faltantes, la normalización y la estandarización de los datos. La eliminación de valores atípicos es el proceso de eliminar valores que son significativamente diferentes de los demás valores en el conjunto de datos. La **interpolación de valores faltantes** es el proceso de reemplazar los valores faltantes con valores estimados a partir de los valores disponibles en los datos. La **normalización y la estandarización** son procesos para transformar los datos en una forma que sea más adecuada para el modelo de inteligencia artificial.

Selección y transformación de características

Después de la limpieza de datos, el siguiente paso es **la selección y transformación de características.** La selección de características es el proceso de seleccionar las variables relevantes para el problema que se está tratando de resolver. La transformación de características es el proceso de transformar las variables en una forma que sea más adecuada para el modelo de inteligencia artificial.

Existen **diferentes técnicas** para la selección y transformación de características, como el **análisis de componentes principales** (PCA), la selección de características basada en modelos, la selección de características basada en la información y la ingeniería de características. El PCA es una técnica que se utiliza para reducir la dimensionalidad de los datos. La selección de características basada en modelos es el proceso de utilizar un modelo para seleccionar las características más importantes. La selección de características basada en la información es el proceso de seleccionar las características que contienen la mayor cantidad de información sobre la variable objetivo. La **ingeniería de características** es el proceso de crear nuevas características a partir de las características existentes.

División de datos

Una vez que los datos se han limpiado y transformado, se deben **dividir en conjuntos de entrenamiento, validación y prueba.** El conjunto de entrenamiento se utiliza para ajustar los parámetros del modelo, el conjunto de validación se utiliza para ajustar los hiperparámetros del modelo y el conjunto de prueba se utiliza para evaluar el rendimiento final del modelo.

Generación de características

La **generación de características** es un paso importante en la preparación de datos para el entrenamiento de modelos de aprendizaje automático. El objetivo de la generación de características es **crear nuevas variables** a partir de las variables existentes que puedan mejorar el rendimiento del modelo. Por ejemplo, si los datos contienen las ventas realizadas en el año, se pueden generar características adicionales a partir de ella, como porcentaje de cumplimiento del objetivo o porcentaje del incremento de ventas respecto al año anterior. La selección de características también es un paso importante, ya que puede reducir la complejidad del modelo y mejorar su rendimiento.

Normalización de datos

La **normalización de datos** es un paso importante en la preparación de datos para el entrenamiento de modelos de aprendizaje automático. La normalización se refiere al proceso de escalar los datos para que tengan una media de cero y una desviación estándar de uno. La normalización es importante porque los modelos de aprendizaje automático pueden ser sensibles a las diferentes escalas de las variables de entrada.

En resumen, la **preparación de datos** es un paso crítico en el proceso de implementación de proyectos de inteligencia artificial. La **calidad de los datos** utilizados en el entrenamiento del modelo es uno de los factores más importantes que afectan el rendimiento del modelo. La limpieza y transformación de datos, la división de datos, la generación de características y la normalización de datos son pasos clave en la preparación de datos para el entrenamiento de modelos de aprendizaje automático.

6.5. Entrenamiento, validación y evaluación de modelos de inteligencia artificial

El **entrenamiento de modelos de inteligencia artificial** es el proceso mediante el cual **se ajustan los parámetros** de un modelo para que pueda hacer **predicciones precisas** sobre nuevos datos. La **validación y evaluación** son técnicas utilizadas para evaluar la calidad del modelo entrenado y su capacidad para generalizar a nuevos datos.

Preparación de datos de entrenamiento

Antes de que un modelo pueda ser entrenado, es necesario **preparar los datos de entrenamiento** como se ha comentado en el apartado de «Gestión y preparación de datos para el entrenamiento de modelos». Esto puede involucrar la **limpieza y la transformación de los datos** para que sean adecuados para el modelo.

La **calidad de los datos** de entrenamiento es crítica para el rendimiento del modelo, por lo que la selección cuidadosa de los datos y la verificación de su calidad son tareas importantes.

Selección de algoritmos y técnicas de aprendizaje automático

La **selección del algoritmo** y las **técnicas de aprendizaje automático** son críticas para el rendimiento del modelo. Diferentes algoritmos y técnicas son más apropiados para diferentes tipos de datos y problemas de predicción. Es importante conocer las **fortalezas y debilidades** de los diferentes enfoques de aprendizaje automático para poder seleccionar la mejor técnica para un problema específico.

Selección de hiperparámetros

Los **hiperparámetros** son los parámetros que no se ajustan durante el entrenamiento del modelo, sino que se establecen antes del entrenamiento. La selección cuidadosa de los hiperparámetros es importante para el rendimiento del modelo.

Ejemplos de hiperparámetros incluyen el número de capas ocultas en una red neuronal, y el número de árboles en un bosque aleatorio.

El **ajuste de hiperparámetros** puede ser un proceso iterativo que implica probar diferentes combinaciones de hiperparámetros y evaluar el rendimiento del modelo en un conjunto de validación.

Entrenamiento del modelo

El **entrenamiento del modelo** es el proceso mediante el cual se ajustan los parámetros del modelo para que haga **predicciones precisas** sobre nuevos datos. El entrenamiento implica la iteración repetida a través de los datos de entrenamiento, con la actualización de los parámetros del modelo después de cada iteración.

Ajuste del modelo

En algunos casos, **es posible que el modelo no alcance el rendimiento deseado** en la evaluación. En este caso, es necesario ajustar el modelo para mejorar su rendimiento. El **ajuste del modelo** implica modificar los hiperparámetros del modelo y realizar un nuevo entrenamiento.

Evaluación del modelo

La **evaluación del modelo** es el proceso de medir la calidad de las predicciones del modelo en nuevos datos. Una vez que el modelo haya sido entrenado y ajustado, se debe **validar su rendimiento** en un conjunto de datos independiente que no se utilizó en el entrenamiento. La evaluación del modelo es importante para verificar que el modelo no esté sobreajustando *(overfitting*) los datos utilizados en el entrenamiento, lo cual podría limitar su capacidad de generalización a nuevos datos. La idea es que el modelo no solo aprenda a predecir bien en los datos utilizados para entrenarlo, sino que también pueda generalizar bien a nuevos datos.

El rendimiento del modelo se mide mediante **métricas de evaluación,** que varían según el tipo de problema que se está abordando. Algunas métricas comunes para la evaluación de modelos de clasificación son:

* **Precisión *(accuracy):*** mide la proporción de predicciones correctas sobre el total de predicciones realizadas.
* ***Recall* (sensibilidad):** mide la proporción de casos positivos que el modelo clasifica correctamente.
* **F1-score:** es una medida que combina la precisión y el *recall* en una sola métrica.

En el caso de modelos de regresión, algunas **métricas comunes** son:

* **Error medio absoluto (MAE):** mide el promedio de las diferencias absolutas entre los valores reales y los valores predichos por el modelo.
* **Error cuadrático medio (MSE):** mide el promedio de los errores al cuadrado entre los valores reales y los valores predichos por el modelo.
* **Coeficiente de determinación (R2):** mide la proporción de la varianza total de los valores predichos por el modelo en relación a los valores reales.

Es importante **seleccionar las métricas de evaluación adecuadas** según el tipo de problema que se esté abordando, ya que algunas métricas pueden ser más apropiadas que otras dependiendo del contexto del proyecto. Por ejemplo, no es lo mismo el peso que tienen los falsos negativos en un problema de predicción de enfermedades donde la no identificación a tiempo de una enfermedad puede acarrear consecuencias graves, que en un problema de predicción de abandono de los clientes de una empresa.

6.6. Integración y despliegue de modelos en un entorno productivo empresarial

Una vez que se han entrenado y evaluado los modelos de inteligencia artificial, el siguiente paso es **integrarlos en un entorno productivo y desplegarlos para su uso** en aplicaciones empresariales. La **integración y despliegue exitoso** de los modelos es crucial para la adopción y utilización de la inteligencia artificial en el negocio. En esta sección, se describirán los **pasos necesarios** para integrar y desplegar modelos en un entorno productivo empresarial.

Selección del entorno de producción

Para integrar y desplegar modelos, se debe **seleccionar el entorno de producción adecuado.** El entorno debe proporcionar las capacidades necesarias para cargar, ejecutar y escalar modelos. Además, el entorno debe cumplir con los **requisitos de seguridad y privacidad** de la empresa. Estos entornos se habrán identificado ya en la fase inicial de análisis y definición de la solución.

Preparación del modelo para la implementación

Antes de integrar y desplegar un modelo, es necesario **prepararlo para su implementación.** Esto puede incluir la conversión del modelo a un formato adecuado para que pueda ser utilizado con el resto del software del entorno de producción.

Creación de un servicio de predicción

Para permitir el uso del modelo en una aplicación empresarial, se debe crear un **servicio de predicción basado en el modelo.** Este servicio debe aceptar solicitudes de predicción, pasar los datos a través del modelo y devolver las predicciones al solicitante. El servicio de predicción también debe ser capaz de manejar la carga y escalar a medida que aumenta el tráfico de solicitudes.

Integración del servicio de predicción en la aplicación empresarial

Una vez que se ha creado el servicio de predicción**, debe integrarse en la aplicación empresarial.** Esto puede incluir la **creación de una interfaz de programación de aplicaciones (API)** para permitir que la aplicación solicite predicciones del modelo y la integración del servicio de predicción en el flujo de trabajo de la aplicación.

Pruebas y validación del servicio de predicción

Después de integrar el servicio de predicción en la aplicación empresarial, es importante realizar **pruebas exhaustivas para garantizar que el servicio funcione correctamente.** Las pruebas deben incluir pruebas unitarias, pruebas de integración y pruebas de rendimiento para garantizar que el servicio cumpla con los requisitos de calidad y rendimiento de la empresa.

Despliegue y monitorización del servicio de predicción

Una vez que se han completado las pruebas y validaciones, se puede desplegar el **servicio de predicción en el entorno productivo.** Es importante **monitorizar continuamente** el servicio para detectar y resolver cualquier problema que pueda surgir. La monitorización también puede proporcionar información valiosa sobre el rendimiento del servicio y ayudar a identificar áreas de mejora.

En general, la monitorización analiza no solo el rendimiento de los modelos con base en parámetros como la precisión, coeficientes de determinación, etc., al igual que se hacía en la fase de evaluación, sino que también se focaliza en el desempeño que está teniendo el modelo como cualquier otro elemento de *software* (tiempos de respuesta, carga simultánea, etc.).

Es importante también establecer **umbrales de alerta** para detectar posibles errores en los resultados del modelo. Si se superan estos umbrales, se debe notificar al equipo responsable de la gestión del modelo para que pueda llevar a cabo las acciones necesarias.

Actualización y mantenimiento del servicio de predicción

A medida que los modelos y las necesidades empresariales cambian, es posible que sea necesario **actualizar y mantener el servicio de predicción.** Esto puede incluir la actualización del modelo subyacente y la modificación del servicio para adaptarse a nuevos requisitos empresariales. Es importante establecer un plan de mantenimiento y actualización del servicio para garantizar su eficacia.

6.7. Referencias bibliográficas

Russell, S., y Norvig, P. (2016). *Artificial Intelligence: A Modern Approach* (4th ed.). Pearson.

Solé, J. M. (2020). *Proyectos de Inteligencia Artificial*. Amazon [distribuidor].

Taylor, P. (202). *AI and the Project Manager. How the Rise of Artificial Intelligence Will Change Your World*. Routledge.

A fondo

How will AI change the world?

Este vídeo explora las limitaciones de la inteligencia artificial y la posibilidad de crear tecnología compatible con humanos.

Accede al vídeo a través del aula virtual o desde la siguiente dirección web: <https://www.youtube.com/watch?v=RzkD_rTEBYs>

Artificial Intelligence: How it will impact Project Managers

Este vídeo aborda elementos de reflexión como cuál es el impacto de la inteligencia artificial en la gestión de proyectos o cómo los jefes de proyecto pueden aprovechar la inteligencia artificial.

Accede al vídeo a través del aula virtual o desde la siguiente dirección web: <https://www.youtube.com/watch?v=iizxHlbOrEM>

Test

1. La fase de análisis del problema dentro de la estructura de un proyecto:

A. Incorpora el análisis de las necesidades y objetivos del negocio.

B. Incluye el análisis técnico para poder evaluar si la solución se puede abordar desde un proyecto de inteligencia artificial.

C. Es el primer paso en la definición de una solución de inteligencia artificial.

\_ D. Todas las respuestas son válidas.

Antes de comenzar a diseñar una solución de inteligencia artificial es esencial comprender las necesidades y objetivos del negocio, así como evaluar si la solución se puede abordar desde un proyecto de inteligencia artificial.

1. Las plataformas de automatización de procesos robóticos (RPA) con capacidades de inteligencia artificial:

\_ A. Se consideran posibles herramientas a emplear en los proyectos de inteligencia artificial por su capacidad de automatizar tareas repetitivas.

B. Son plataformas de aprendizaje MLaaS.

C. Suelen ser herramientas comerciales orientadas al desarrollo de casos de uso específicos como el análisis de datos o el reconocimiento del lenguaje natural.

D. Abarcan desde modelos de aprendizaje a herramientas de gestión de proyectos.

Las plataformas de automatización de procesos robóticos (RPA) con capacidades de IA permiten automatizar tareas repetitivas y basadas en reglas utilizando robots de *software*.

1. Las herramientas y plataformas de inteligencia artificial *open source*:

A. Reducen los costes de desarrollo.

\_ B. Reducen el tiempo de desarrollo.

C. No tienen el soporte de desarrolladores y expertos en la materia.

D. Todas las respuestas son correctas.

Las herramientas y plataformas de desarrollo ofrecen una serie de beneficios como la reducción del tiempo de desarrollo, facilitan la experimentación y la iteración, proporcionan escalabilidad y rendimiento y disponen del soporte de una comunidad amplia de desarrolladores y expertos en la materia.

1. Las herramientas y plataformas de inteligencia artificial presentan desafíos:

A. Coste de las soluciones empresariales.

B. Dependencia de proveedores.

C. Complejidad técnica.

\_ D. Todas las respuestas son correctas.

El uso de herramientas y plataformas IA también presenta desafíos como el coste de las soluciones empresariales, en algunos casos elevado, la dependencia de los proveedores seleccionados o la necesidad de contar con conocimientos técnicos especializados para ser utilizadas de manera efectiva.

1. La selección de las herramientas y plataformas de inteligencia artificial a utilizar en un proyecto debe considerar los siguientes factores:

\_ A. Escalabilidad para adaptarse a las necesidades de crecimiento y expansión de un proyecto.

B. Menor coste posible.

C. Ausencia de sesgo en el tratamiento de datos.

D. Incorporación de fuentes de datos externas que enriquezcan los datos internos disponibles por la empresa.

Es importante seleccionar soluciones que puedan adaptarse a las necesidades cambiantes del proyecto y manejar grandes volúmenes de datos y usuarios, especialmente si se trata de proyectos que pueden crecer en tamaño y complejidad.

1. La gestión y preparación de los datos para el entrenamiento de los modelos:

A. Permite ir más rápido ya que no obliga a documentar.

B. Es especialmente útil donde los requisitos son cambiantes y no están definidos con precisión.

\_ C. Incorpora la recopilación de los datos, su limpieza, selección y transformación de características y la normalización de los datos.

D. Incorpora el entrenamiento y validación de los modelos.

La calidad de los datos de entrada es uno de los factores más importantes en la creación de modelos de inteligencia artificial efectivos. Es por eso que la gestión y preparación adecuada de los datos es esencial para el éxito del proyecto.

1. La selección de algoritmos y técnicas de aprendizaje automático:

\_ A. Implica conocer las fortalezas y debilidades de los diferentes enfoques de aprendizaje automático para poder seleccionar la mejor técnica para un problema específico.

B. Forma parte de la fase de despliegue de los modelos.

C. Incluye la evaluación del rendimiento de los modelos.

D. Todas las respuestas son correctas.

La selección del algoritmo y las técnicas de aprendizaje automático son críticas para el rendimiento del modelo. Diferentes algoritmos y técnicas son más apropiados para diferentes tipos de datos y problemas de predicción y es necesaria una cuidadosa selección en la fase de construcción y entrenamiento de los modelos.

1. La selección de las métricas de evaluación de los modelos de inteligencia artificial:

\_ A. Varía según el tipo de problema que se está abordando.

B. Impone el uso de las mismas métricas para todos los modelos permitiendo así la comparativa universal de su rendimiento.

C. Incluye el posible uso del error exponencial mínimo.

D. Impide identificar el sobreajuste de los modelos.

La evaluación del modelo es el proceso de medir la calidad de las predicciones del modelo en nuevos datos. La idea es que el modelo no solo aprenda a predecir bien en los datos utilizados para entrenarlo, sino que también pueda generalizar bien a nuevos datos.

1. La creación de los servicios de predicción de un modelo:

A. Implica la normalización de los datos.

B. Facilita la auditoría y seguimiento de las actividades relacionadas con el proyecto de inteligencia artificial.

C. Permite la detección de brechas de seguridad.

\_ D. Es una de las fases propia de la integración y despliegue de modelos en los entornos de producción.

Para permitir el uso del modelo en una aplicación empresarial, se debe crear un servicio de predicción basado en el modelo. Este servicio debe aceptar solicitudes de predicción, pasar los datos a través del modelo y devolver las predicciones al solicitante.

1. Las plataformas de aprendizaje automático como servicio (MLaaS) proporcionan un entorno basado en la nube para el desarrollo, entrenamiento y despliegue de modelos. Algunas de ellas son las siguientes:

\_ A. Google Cloud AI Platform.

B. Scikit-learn.

C. OpenCV.

D. Blue Prism.

Google Cloud AI Platform ofrece una variedad de servicios de IA y aprendizaje automático en la nube, incluida la creación, el entrenamiento y el despliegue de modelos, así como servicios de preprocesamiento de datos y análisis de modelos. El resto de las soluciones mencionadas no necesariamente están basadas en soluciones *cloud* y se prestan como servicio.